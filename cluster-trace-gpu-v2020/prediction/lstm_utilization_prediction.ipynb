{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Utilization Prediction\n",
    "\n",
    "This Jupyter Notebook is aimed to test, if the utilization of hardware can be predicted by its historical utilization.\n",
    "For this, a Long-Short Term Memory (LSTM) Neural Networks are used.\n",
    "\n",
    "These are a special kind of Recurrent Neural Networks (RNN), which are capable of learning long-term dependencies.\n",
    "This property fits our use case of trying to predict a future sequential time-series based on a past sequential time-series.\n",
    "\n",
    "\n",
    "## Resources \n",
    "\n",
    "- This notebook relied on the sources:\n",
    "  -  [How to apply LSTM using PyTorch](https://cnvrg.io/pytorch-lstm/) and\n",
    "  -  [Predicting-cloud-CPU-usage-on-Azure-data](https://github.com/amcs1729/Predicting-cloud-CPU-usage-on-Azure-data).\n",
    "- [Further Reading on LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Python Modules\n",
    "\n",
    "*Note: If you encounter an error while trying to load the modules, go to the README.md for installing infos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# used for statistical processes, i.e scaling the dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "# plotting the data\n",
    "import matplotlib.pyplot as plt\n",
    "# used for the dataframes\n",
    "import pandas as pd\n",
    "# transforming dataframes into arrays\n",
    "# and those arrays to Tensors, the ML approach can work with\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# required for the LSTM model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataframe\n",
    "\n",
    "In this cell the dataframe with the machine utilization data will be loaded and prepared if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training_machine_sorted_df.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['start_date'])\n",
    "df = df.set_index('timestamp')\n",
    "# df = df.sort_index()\n",
    "df.drop(columns=['start_date'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('machine').count()\n",
    "\n",
    "df = df.query(\"machine == 'ffb1bc4dc2fbb09d0477f0f0'\")\n",
    "df = df.drop(columns=['machine', 'gpu_type', 'job_name'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add One-Hot Encoded Columns for Taskname\n",
    "\n",
    "In order to process categorical data, in this case the `task_name` column, we need to encode it.\n",
    "\n",
    "For this, we use the `pandas.get_dummies()` method that returns the `task_name` column as one-hot encoded columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df.task_name)\n",
    "dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the One-Hot Encoded Columns\n",
    "\n",
    "After generating the one-hot encoded columns for `task_name`, we append it to the dataframe.\n",
    "Afterwards, we remove the `task_name` column since it is now represented by those appended columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(dummies)\n",
    "df.drop(columns=['task_name'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Dataframe into Train and Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LENGTH = round(len(df) * 0.8)\n",
    "TEST_LENGTH = len(df) - TRAIN_LENGTH\n",
    "train = df.iloc[0:TRAIN_LENGTH]\n",
    "test = df[TRAIN_LENGTH:]\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the Datasets\n",
    "\n",
    "In this step the train and test datasets are scaled to represent the data values in a (-1, 1) interval.\n",
    "This is done to omit unwanted behaviour by the machine learning model. \n",
    "\n",
    "[Code Source](https://cnvrg.io/pytorch-lstm/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_scaler = StandardScaler()\n",
    "mm_scaler = MinMaxScaler()\n",
    "# mm_scaler = StandardScaler()\n",
    "\n",
    "y_range = ['cpu_usage', 'gpu_wrk_util', 'avg_mem', 'max_mem',\n",
    "       'avg_gpu_wrk_mem', 'max_gpu_wrk_mem', 'runtime']\n",
    "\n",
    "X_ss = pd.DataFrame(ss_scaler.fit_transform(train))\n",
    "y_mm = pd.DataFrame(mm_scaler.fit_transform(test[y_range]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Dataset\n",
    "\n",
    "Now the dataset gets split into test and training dataset.\n",
    "\n",
    "*Note: To later be able to convert the dataset into Tensors, it is necessary to convert them to numpy arrays via `.to_numpy()`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT: int = 600\n",
    "TEST_SPLIT = TRAIN_SPLIT + 100\n",
    "\n",
    "X_train = X_ss[:TRAIN_SPLIT].to_numpy()\n",
    "X_test = X_ss[TRAIN_SPLIT:TEST_SPLIT].to_numpy()\n",
    "\n",
    "y_train = y_mm[:TRAIN_SPLIT].to_numpy()\n",
    "y_test = y_mm[TRAIN_SPLIT:TEST_SPLIT].to_numpy()\n",
    "\n",
    "print(\"Training Shape\", X_train.shape, y_train.shape)\n",
    "print(\"Testing Shape\", X_test.shape, y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the Datasets to Tensors\n",
    "\n",
    "In order to be able to use the datasets with PyTorch, we first have to convert them to Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensors = Variable(torch.Tensor(X_train))\n",
    "X_test_tensors = Variable(torch.Tensor(X_test))\n",
    "\n",
    "y_train_tensors = Variable(torch.Tensor(y_train))\n",
    "y_test_tensors = Variable(torch.Tensor(y_test))\n",
    "\n",
    "y_train_tensors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping to Rows, Timestamps and Features\n",
    "\n",
    "In the reshaping process, we add an additional dimension.\n",
    "\n",
    "This is done, because LSTMs are built for sequential data and cannot \"comprehend\" simple 2-D data as its input.\n",
    "They need to also have the timestamp information with them, so they can work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "X_train_tensors_final = torch.reshape(X_train_tensors, (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\n",
    "X_test_tensors_final = torch.reshape(X_test_tensors, (X_test_tensors.shape[0], 1, X_test_tensors.shape[1]))\n",
    "\n",
    "print(\"Training Shape\", X_train_tensors_final.shape, y_train_tensors.shape)\n",
    "print(\"Testing Shape\", X_test_tensors_final.shape, y_test_tensors.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the LSTM Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes: int, input_size: int, hidden_size: int, num_layers: int, seq_length: int) -> None:\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_classes: int = num_classes\n",
    "        self.input_size: int = input_size\n",
    "        self.hidden_size: int = hidden_size\n",
    "        self.num_layers: int = num_layers\n",
    "        self.seq_length: int = seq_length\n",
    "\n",
    "        # long-short term memory layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True)\n",
    "\n",
    "        # first fully connected layer\n",
    "        self.fc_1 = nn.Linear(hidden_size, 256)\n",
    "        # second fully connected layer\n",
    "        self.fc_2 = nn.Linear(256, 128)\n",
    "        # thrid fully connected layer\n",
    "        self.fc_3 = nn.Linear(128, num_classes)\n",
    "        # activation function\n",
    "        self.relu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, input):\n",
    "        hidden_state = Variable(torch.zeros(self.num_layers, input.size(0), self.hidden_size))\n",
    "        internal_state = Variable(torch.zeros(self.num_layers, input.size(0), self.hidden_size))\n",
    "\n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(input, (hidden_state, internal_state))\n",
    "        # Reshaping the data for the Dense layer\n",
    "        hn = hn.view(-1, self.hidden_size)\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc_1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc_2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc_3(out)\n",
    "        \n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining some hyperparameters\n",
    "\n",
    "In the following cell, some hyperparameters are defined for further usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs: int = 1000\n",
    "learning_rate: float = 0.005\n",
    "\n",
    "# number of features\n",
    "input_size: int = len(train.columns)\n",
    "# number of features in hidden state\n",
    "hidden_size: int = len(train.columns) * 2\n",
    "# number of stacked lstm layers\n",
    "num_layers: int = 1\n",
    "# number of output classes\n",
    "num_classes: int = len(y_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the LSTM object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers, X_train_tensors_final.shape[1])\n",
    "lstm.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean squared error for regression\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer function\n",
    "optimizer = torch.optim.AdamW(lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "In the following, the training of the LSTM model is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # forward pass\n",
    "    outputs = lstm.forward(X_train_tensors_final)\n",
    "    # calculates the gradient and manually setting to 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # obtain the loss function\n",
    "    loss = criterion(outputs, y_train_tensors)\n",
    "\n",
    "    # calculates the loss of the loss function\n",
    "    loss.backward()\n",
    "\n",
    "    # improve from loss, i.e backpropagation\n",
    "    optimizer.step()  \n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old transformers\n",
    "df_X_ss = ss_scaler.transform(df)\n",
    "df_y_mm = mm_scaler.transform(df[y_range])\n",
    "\n",
    "# converting to Tensors\n",
    "df_X_ss = Variable(torch.Tensor(df_X_ss))\n",
    "df_y_mm = Variable(torch.Tensor(df_y_mm))\n",
    "\n",
    "# reshaping the dataset\n",
    "df_X_ss = torch.reshape(df_X_ss, (df_X_ss.shape[0], 1, df_X_ss.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Mode\n",
    "lstm.eval()\n",
    "\n",
    "# forward pass\n",
    "train_predict = lstm(df_X_ss)\n",
    "data_predict = train_predict.data.numpy()\n",
    "data_predict = ss_scaler.fit_transform(data_predict)\n",
    "\n",
    "dataY_plot = df_y_mm.data.numpy()\n",
    "dataY_plot = mm_scaler.fit_transform(dataY_plot)\n",
    "\n",
    "# reverse transformation\n",
    "data_predict = ss_scaler.inverse_transform(data_predict)  \n",
    "dataY_plot = mm_scaler.inverse_transform(dataY_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_predict_df = pd.DataFrame(data_predict, columns=y_range)\n",
    "data_y_plot_df = pd.DataFrame(dataY_plot, columns=y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error (RMSE)\n",
    "\n",
    "$\\operatorname{RMSD}(\\hat{\\theta}) = \\sqrt{\\operatorname{MSE}(\\hat{\\theta})} = \\sqrt{\\operatorname{E}((\\hat{\\theta}-\\theta)^2)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_rmse(actual_values, predicted_values) -> float:\n",
    "    return math.sqrt(mean_squared_error(actual_values, predicted_values))\n",
    "\n",
    "rmse_result = get_rmse(dataY_plot[:], data_predict_df[:])\n",
    "print(f'Test Score: {rmse_result:.2f} RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error (MAE)\n",
    "\n",
    "$\\mathrm {MAE} ={\\frac {\\sum _{i=1}^{n}\\left|y_{i}-x_{i}\\right|}{n}}={\\frac {\\sum _{i=1}^{n}\\left|e_{i}\\right|}{n}}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_result = mean_absolute_error(dataY_plot[:], data_predict_df[:])\n",
    "print(f'Test Score: {mae_result} MAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Percentage Error (MAPE)\n",
    "\n",
    "$MAPE={\\frac {100\\%}{n}}\\sum _{t=1}^{n}\\left|{\\frac {A_{t}-F_{t}}{A_{t}}}\\right|$\n",
    "\n",
    "The **mean absolute percentage error (MAPE)**, is a measure of prediction accuracy of a forecasting (prediction) method in statistics.\n",
    "\n",
    "$A_t$ is the actual value and $F_t$ is the predicted value. Their difference is divided by the actual value $A_t$. \n",
    "\n",
    "The absolute value in this ration is summed for every predicted point in time and divided by the number of fitted points $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mape(actual_values, predicted_values):\n",
    "    return np.mean(np.abs(actual_values - predicted_values) / np.abs(actual_values) * 100)\n",
    "\n",
    "mape_result = get_mape(dataY_plot, data_predict_df)\n",
    "print(f'Test Score: {mape_result} MAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_column(actual_values = data_y_plot_df, predicted_values = data_predict_df, column_number: int = 0, rmse_threshold: float = 0.30):\n",
    "    \n",
    "    if len(y_range) <= column_number:\n",
    "        print('Out of Prediction Bounds')\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(25, 15))  # plotting\n",
    "    pred_colums = ['pred_' + col for col in y_range]\n",
    "\n",
    "    column = y_range[column_number]\n",
    "\n",
    "    rmse = get_rmse(actual_values[column], predicted_values[column])\n",
    "    mae = mean_absolute_error(actual_values[column], predicted_values[column])\n",
    "    \n",
    "    predicted_color = 'green' if rmse < rmse_threshold else 'orange'\n",
    "\n",
    "    plt.plot(actual_values[column], label=column, color='black')  # actual plot\n",
    "    plt.plot(predicted_values[column], label='pred_' + column, color=predicted_color)  # predicted plot\n",
    "    \n",
    "    plt.title('Time-Series Prediction')\n",
    "    plt.plot([], [], ' ', label=f'RMSE: {rmse}')\n",
    "    plt.plot([], [], ' ', label=f'MAE: {mae}')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_column(column_number=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_column(column_number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_column(column_number=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_column(column_number=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_column(column_number=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_column(column_number=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_column(column_number=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml_pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc289c9585466324d6bcd715c701435d361dd4760f0e3d7325b29a75549769c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
